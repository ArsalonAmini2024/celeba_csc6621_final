{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final project \"sandbox\" for CSC6621 - Arsalon's Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# not required if using the Docker Image \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction successful.\n"
     ]
    }
   ],
   "source": [
    "from pyunpack import Archive\n",
    "\n",
    "# Define the path to the directory containing the split archive\n",
    "archive_directory = 'data/img_celeba.7z'\n",
    "\n",
    "# Specify the first file of the split archive\n",
    "first_part_path = os.path.join(archive_directory, 'img_celeba.7z.001')\n",
    "\n",
    "# Define the output directory for the extracted files\n",
    "output_directory = 'data/img_celeba_extracted'\n",
    "\n",
    "# Extract the archive\n",
    "try:\n",
    "    Archive(first_part_path).extractall(output_directory)\n",
    "    print(\"Extraction successful.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to extract:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files successfully split into training and testing directories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the output directory from previous context\n",
    "output_directory = 'data/img_celeba_extracted'\n",
    "\n",
    "# Path to the directory where all images are stored\n",
    "image_directory = os.path.join(output_directory, 'img_celeba')\n",
    "\n",
    "# Define the train and test directories\n",
    "train_dir = os.path.join(output_directory, 'train')\n",
    "test_dir = os.path.join(output_directory, 'test')\n",
    "\n",
    "# Create directories for train and test datasets if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get all file names in the output directory\n",
    "all_files = [os.path.join(image_directory, f) for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
    "\n",
    "# Split files into train and test sets (80-20 split here)\n",
    "train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to copy files to new directories\n",
    "def copy_files(files, directory):\n",
    "    for file in files:\n",
    "        shutil.copy(file, directory)\n",
    "\n",
    "# Copy files to respective directories\n",
    "copy_files(train_files, train_dir)\n",
    "copy_files(test_files, test_dir)\n",
    "\n",
    "print(\"Files successfully split into training and testing directories.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator: \n",
    "\n",
    "-From Tensorflow helps performing operations such as rescaling, rotating, shifting, shearing, and flipping. \n",
    "-Reads images in large numbers from a directory and automatically feed them to the model in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129664 validated image filenames belonging to 10153 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 40520 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32415 validated image filenames belonging to 10153 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 40520 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40520 validated image filenames belonging to 9362 classes.\n",
      "Input batch shape: (32, 64, 64, 3)\n",
      "Label batch shape: (32, 10153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 162079 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "train_dir = 'data/img_celeba_extracted/train'  \n",
    "test_dir = 'data/img_celeba_extracted/test'    \n",
    "\n",
    "# Load the labels dataset and ensure labels are string type\n",
    "file_path = os.path.join(os.getcwd(), 'data', 'identity_CelebA.txt')\n",
    "data = pd.read_csv(file_path, delim_whitespace=True, header=None, names=['filename', 'label'])\n",
    "data['label'] = data['label'].astype(str)  # Convert labels to string to match expected format\n",
    "\n",
    "# Check file existence for train, test, and validate subsets\n",
    "data['train_exists'] = data['filename'].apply(lambda x: os.path.exists(os.path.join(train_dir, x)))\n",
    "data['test_exists'] = data['filename'].apply(lambda x: os.path.exists(os.path.join(test_dir, x)))\n",
    "\n",
    "# Separate DataFrames for train, test based on file existence\n",
    "train_data = data[data['train_exists']]\n",
    "test_data = data[data['test_exists']]\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Train Generator - updated class_mode to 'categorical'\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    directory=train_dir,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(64, 64),  # Resizes all images to 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  \n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation Generator (from train data) - also 'categorical'\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    directory=train_dir,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Test Generator - also 'categorical'\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    directory=test_dir,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Print the shapes of input images and labels from the generator\n",
    "inputs, labels = next(train_generator)\n",
    "print('Input batch shape:', inputs.shape)\n",
    "print('Label batch shape:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/var/folders/32/7pznm6jd5rz3p46wf8k0bs6w0000gn/T/ipykernel_8822/3734479341.py\", line 20, in <module>\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/backend.py\", line 5579, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[32,10177] labels_size=[32,10153]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_36655]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs to train for\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data to evaluate the model\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/Users/arsalonamini/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/var/folders/32/7pznm6jd5rz3p46wf8k0bs6w0000gn/T/ipykernel_8822/3734479341.py\", line 20, in <module>\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/backend.py\", line 5579, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[32,10177] labels_size=[32,10153]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_36655]"
     ]
    }
   ],
   "source": [
    "# Number of classes\n",
    "num_classes = 10153\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Update for 10,177 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Number of epochs to train for\n",
    "    validation_data=test_generator  # Validation data to evaluate the model\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
